{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Image Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import glob\n",
    "import pickle\n",
    "from helperfunctions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Camera Calibration and Initialize Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Project_Output/cam_calib_res.p\", mode='rb') as f:\n",
    "    camera_calib = pickle.load(f)\n",
    "mtx = camera_calib[\"mtx\"]\n",
    "dist = camera_calib[\"dist\"]\n",
    "Test_images = glob.glob(\"test_images/*.jpg\")\n",
    "showimages=False\n",
    "saveimages=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Distortion Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get a test image to undistort\n",
    "\n",
    "for fname in Test_images:\n",
    "\n",
    "    # Read in image\n",
    "    #img = cv2.imread(fname)\n",
    "    example_distorted_test_image = cv2.imread(fname)\n",
    "    example_distorted_test_image_RGB = cv2.cvtColor(example_distorted_test_image, cv2.COLOR_BGR2RGB)\n",
    "    example_undistorted_test_image = cv2.undistort(example_distorted_test_image_RGB,mtx,dist)\n",
    "\n",
    "    # Display the distorted test alongside its undistorted counterpart\n",
    "\n",
    "    if showimages:\n",
    "        fig=plt.figure(figsize=(20,10))\n",
    "        plt.subplot(121),plt.imshow(example_distorted_test_image_RGB)\n",
    "        plt.title('Distorted', fontsize=30)\n",
    "        plt.subplot(122),plt.imshow(example_undistorted_test_image)\n",
    "        plt.title('Undistorted', fontsize=30)\n",
    "        fig.suptitle(fname, fontsize=16)\n",
    "    if saveimages:\n",
    "        mpimg.imsave(\"Undistorted_\"+fname,example_undistorted_test_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Color Transforms & Gradient Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_binary_image_v1(image, sobel_thresholds=(30, 140), color_thresholds=(150, 255)):\n",
    "    image = np.copy(image)\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    sxbinary_l= abs_sobel_thresh(l_channel, orient='x', sobel_kernel=3, thresh=sobel_thresholds)\n",
    "    sxbinary_s= abs_sobel_thresh(s_channel, orient='x', sobel_kernel=3, thresh=sobel_thresholds)   \n",
    "      \n",
    "    # Thresholding on the color channels\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= color_thresholds[0]) & (s_channel <= color_thresholds[1])] = 1\n",
    "    l_binary = np.zeros_like(l_channel)\n",
    "    l_binary[(l_channel >= 60) & (l_channel <= 230)] = 1\n",
    "    \n",
    "    combined = np.zeros_like(s_channel)\n",
    "    combined[((s_binary == 1) & (l_binary == 1)) | (sxbinary_s == 1)|(sxbinary_l==1)] = 1     \n",
    "\n",
    "    return combined\n",
    "def generate_binary_image_v2(image, sobel_thresholds=(30, 140), color_thresholds=(150, 255)):\n",
    "    image = np.copy(image)\n",
    "\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    sxbinary_l= abs_sobel_thresh(l_channel, orient='x', sobel_kernel=3, thresh=sobel_thresholds)\n",
    "    sxbinary_s= abs_sobel_thresh(s_channel, orient='x', sobel_kernel=3, thresh=sobel_thresholds)   \n",
    "      \n",
    "    # Thresholding on the color channels\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= color_thresholds[0]) & (s_channel <= color_thresholds[1])] = 1\n",
    "    \n",
    "    combined = np.zeros_like(s_channel)\n",
    "    combined[(s_binary == 1) | (sxbinary_s == 1)|(sxbinary_l==1)] = 1     \n",
    "\n",
    "    return combined\n",
    "def generate_binary_image_v3(image, sobel_thresholds=(30, 140), color_thresholds=(150, 255)):\n",
    "    # Convert to YCrCb color space\n",
    "    img = np.copy(image)\n",
    "    YCrCb = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    mask_YCrCb = cv2.bitwise_or(cv2.inRange(YCrCb[:, :, 2], 0, 100), cv2.inRange(YCrCb[:, :, 1], 150, 255))  \n",
    "    \n",
    "    LAB = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    mask_LAB = cv2.bitwise_and(cv2.inRange(LAB[:, :, 0], 210, 255),cv2.inRange(LAB[:, :, 1], 123, 132), cv2.inRange(LAB[:, :, 2],  123, 132)) \n",
    "    return cv2.bitwise_or(mask_YCrCb,mask_LAB)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_binary_image(image, sobel_thresholds=(30, 140), color_thresholds=(150, 255)):\n",
    "    return generate_binary_image_v3(image, sobel_thresholds=(30, 140), color_thresholds=(150, 255))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the before and after\n",
    "for fname in Test_images:\n",
    "    example_distorted_test_image = cv2.imread(fname)\n",
    "    example_distorted_test_image_RGB = cv2.cvtColor(example_distorted_test_image, cv2.COLOR_BGR2RGB)\n",
    "    example_undistorted_test_image = cv2.undistort(example_distorted_test_image_RGB,mtx,dist)    \n",
    "    result1=generate_binary_image_v1(example_undistorted_test_image)\n",
    "    result2=generate_binary_image_v2(example_undistorted_test_image)\n",
    "    result3=generate_binary_image_v3(example_undistorted_test_image)\n",
    "    result=generate_binary_image(example_undistorted_test_image)\n",
    "    if showimages:\n",
    "        fig= plt.figure(figsize=(20,10))\n",
    "        plt.subplot(141),plt.imshow(example_undistorted_test_image)\n",
    "        plt.title('Before', fontsize=30)\n",
    "        plt.subplot(142),plt.imshow(result1, cmap='gray')\n",
    "        plt.title('v1', fontsize=30)\n",
    "        plt.subplot(143),plt.imshow(result2, cmap='gray')\n",
    "        plt.title('v2', fontsize=30)\n",
    "        plt.subplot(144),plt.imshow(result3, cmap='gray')\n",
    "        plt.title('v3', fontsize=30)\n",
    "       # fig.suptitle(fname, fontsize=16)\n",
    "\n",
    "    if saveimages:\n",
    "        mpimg.imsave(\"Transformed_\"+fname,result, cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 2.3 Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warper(image):\n",
    "    image_size = image.shape[:2]\n",
    "    img_size = (image_size[1], image_size[0])  \n",
    "    \n",
    "    src = np.float32(\n",
    "        [[259, 692],\n",
    "         [608, 444],\n",
    "         [672, 444],\n",
    "         [1160, 692]])\n",
    "\n",
    "    dst = np.float32(\n",
    "        [[200,720],\n",
    "         [200,0],\n",
    "         [1047,0],\n",
    "         [1047,720]])\n",
    "  \n",
    "    perspective_matrix = cv2.getPerspectiveTransform(src, dst)\n",
    "    inverse_warp_matrix = cv2.getPerspectiveTransform(dst, src)\n",
    "    warped = cv2.warpPerspective(image, perspective_matrix, img_size)\n",
    "    return warped, inverse_warp_matrix\n",
    "\n",
    "#https://nikolasent.github.io/opencv/2017/05/07/Bird's-Eye-View-Transformation.html\n",
    "#https://nikolasent.github.io/proj/proj1\n",
    "def warper_V2(image):\n",
    "    image_size = image.shape[:2]\n",
    "    img_size = (1280, 223)  \n",
    "    src = np.float32([[0, 673],   [1207, 673],[0, 450], [1280, 450]])\n",
    "    dst = np.float32([[569, 223], [711, 223], [0, 0],   [1280, 0]])\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M = cv2.getPerspectiveTransform(src, dst) # The transformation matrix\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src) # Inverse transformation\n",
    "\n",
    "    img = np.copy(image) # Read the test img\n",
    "   # img = img[450:(450+IMAGE_H), 0:IMAGE_W] # Apply np slicing for ROI crop\n",
    "    warped_img = cv2.warpPerspective(img, M,img_size) # Image warping\n",
    "    #plt.imshow(cv2.cvtColor(warped_img, cv2.COLOR_BGR2RGB)) # Show results\n",
    "    #plt.show()\n",
    "    return warped_img, Minv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Display the before and after\n",
    "for fname in Test_images:\n",
    "    example_distorted_test_image = cv2.imread(fname)\n",
    "    example_distorted_test_image_RGB = cv2.cvtColor(example_distorted_test_image, cv2.COLOR_BGR2RGB)\n",
    "    example_undistorted_test_image = cv2.undistort(example_distorted_test_image_RGB,mtx,dist)    \n",
    "    warped, inverse_warp_matrix =warper_V2(example_undistorted_test_image) \n",
    "\n",
    "    if showimages:\n",
    "        fig=plt.figure(figsize=(20,10))\n",
    "        plt.subplot(121),plt.imshow(example_undistorted_test_image)\n",
    "        plt.title('Before', fontsize=30)\n",
    "        plt.subplot(122),plt.imshow(warped)\n",
    "        plt.title('After', fontsize=30)\n",
    "        fig.suptitle(fname, fontsize=16)\n",
    "\n",
    "    if saveimages:\n",
    "       mpimg.imsave(\"Warped_\"+fname,warped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Identify lane-line pixels and fit a polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the before and after\n",
    "for fname in Test_images:\n",
    "    example_distorted_test_image = cv2.imread(fname)\n",
    "    example_distorted_test_image_RGB = cv2.cvtColor(example_distorted_test_image, cv2.COLOR_BGR2RGB)\n",
    "    example_undistorted_test_image = cv2.undistort(example_distorted_test_image_RGB,mtx,dist)\n",
    "    binary = generate_binary_image(example_undistorted_test_image)\n",
    "    warped, inverse_warp_matrix =warper_V2(binary) \n",
    "\n",
    "    if showimages:\n",
    "        fig=plt.figure(figsize=(20,10))\n",
    "        plt.subplot(121),plt.imshow(example_undistorted_test_image)\n",
    "        plt.title('Before', fontsize=30)\n",
    "        plt.subplot(122),plt.imshow(warped, cmap='gray')\n",
    "        plt.title('After', fontsize=30)\n",
    "        fig.suptitle(fname, fontsize=16)\n",
    "    if saveimages:\n",
    "        mpimg.imsave(\"Transformed_Warped_\"+fname,warped, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_lane_search(image, left_fit, right_fit):\n",
    "    output_buffer = np.dstack((image, image, image))*255\n",
    "    \n",
    "    # Get a histogram of the bottom part of the image\n",
    "    histogram = np.sum(image[np.int(image.shape[0]*1 / 2):, 569:711], axis=0)\n",
    "    #plt.figure()\n",
    "    #plt.plot(histogram)\n",
    "\n",
    "    # Discover possible starting points for the left and right lines \n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    left_x_base = np.argmax(histogram[:midpoint])+569\n",
    "    right_x_base = np.argmax(histogram[midpoint:]) + midpoint+569\n",
    "\n",
    "    num_windows = 9\n",
    "    window_height = np.int(image.shape[0]/num_windows)\n",
    "\n",
    "    # x/y positions of all nonzeros in the image\n",
    "    nonzero = image.nonzero()\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "\n",
    "    # Position buffers for use when moving from window to window\n",
    "    # Starts at our possible starting points\n",
    "    current_left_x = left_x_base\n",
    "    current_right_x = right_x_base\n",
    "\n",
    "    # Margine on each side of each window?\n",
    "    margin = 10\n",
    "\n",
    "    # Minimum pixels to recenter a window?\n",
    "    recenter_minimum = 3\n",
    "\n",
    "    # Buffers for left and right lane pixel indices\n",
    "    left_lane_indices = []\n",
    "    right_lane_indices = []\n",
    "\n",
    "    for window in range(num_windows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = image.shape[0] - (window + 1) * window_height\n",
    "        win_y_high = image.shape[0] - window * window_height\n",
    "        win_xleft_low = current_left_x - margin\n",
    "        win_xleft_high = current_left_x + margin\n",
    "        win_xright_low = current_right_x - margin\n",
    "        win_xright_high = current_right_x + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(\n",
    "            output_buffer,\n",
    "            (win_xleft_low, win_y_low),\n",
    "            (win_xleft_high, win_y_high),\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        ) \n",
    "        cv2.rectangle(\n",
    "            output_buffer,\n",
    "            (win_xright_low, win_y_low),\n",
    "            (win_xright_high, win_y_high),\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        ) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_indices = (\n",
    "            (nonzero_y >= win_y_low) & \n",
    "            (nonzero_y < win_y_high) & \n",
    "            (nonzero_x >= win_xleft_low) & \n",
    "            (nonzero_x < win_xleft_high)).nonzero()[0]\n",
    "        good_right_indices = (\n",
    "            (nonzero_y >= win_y_low) & \n",
    "            (nonzero_y < win_y_high) & \n",
    "            (nonzero_x >= win_xright_low) & \n",
    "            (nonzero_x < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_indices.append(good_left_indices)\n",
    "        right_lane_indices.append(good_right_indices)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_indices) > recenter_minimum:\n",
    "            current_left_x = np.int(np.mean(nonzero_x[good_left_indices]))\n",
    "        if len(good_right_indices) > recenter_minimum:        \n",
    "            current_right_x = np.int(np.mean(nonzero_x[good_right_indices]))\n",
    "            \n",
    "    left_lane_indices = np.concatenate(left_lane_indices)\n",
    "    right_lane_indices = np.concatenate(right_lane_indices)\n",
    "    \n",
    "    left_x = nonzero_x[left_lane_indices]\n",
    "    left_y = nonzero_y[left_lane_indices]\n",
    "    right_x = nonzero_x[right_lane_indices]\n",
    "    right_y = nonzero_y[right_lane_indices]\n",
    "    \n",
    "    try:\n",
    "        new_left_fit = np.polyfit(left_y, left_x, 2)\n",
    "    except TypeError:\n",
    "        new_left_fit = left_fit\n",
    "    try:\n",
    "        new_right_fit = np.polyfit(right_y, right_x, 2)\n",
    "    except TypeError:\n",
    "        new_right_fit = right_fit\n",
    "    \n",
    "    # Do visualization\n",
    "\n",
    "    output_buffer[nonzero_y[left_lane_indices], nonzero_x[left_lane_indices]] = [255, 0, 0]\n",
    "    output_buffer[nonzero_y[right_lane_indices], nonzero_x[right_lane_indices]] = [0, 0, 255]\n",
    "    \n",
    "    return new_left_fit, new_right_fit, output_buffer, right_x, right_y, left_x, left_y\n",
    "\n",
    "\n",
    "def preexisting_lane_search(image, left_fit, right_fit):\n",
    "    output_buffer = np.dstack((image, image, image))*255\n",
    "    nonzero = image.nonzero()\n",
    "    nonzero_y = np.array(nonzero[0])\n",
    "    nonzero_x = np.array(nonzero[1])\n",
    "    margin = 10\n",
    "    left_lane_indices = ((nonzero_x > (left_fit[0]*(nonzero_y**2) + left_fit[1]*nonzero_y + left_fit[2] - margin)) & (nonzero_x < (left_fit[0]*(nonzero_y**2) + left_fit[1]*nonzero_y + left_fit[2] + margin))) \n",
    "    right_lane_indices = ((nonzero_x > (right_fit[0]*(nonzero_y**2) + right_fit[1]*nonzero_y + right_fit[2] - margin)) & (nonzero_x < (right_fit[0]*(nonzero_y**2) + right_fit[1]*nonzero_y + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    left_x = nonzero_x[left_lane_indices]\n",
    "    left_y = nonzero_y[left_lane_indices] \n",
    "    right_x = nonzero_x[right_lane_indices]\n",
    "    right_y = nonzero_y[right_lane_indices]\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    try:\n",
    "        left_fit = np.polyfit(left_y, left_x, 2)\n",
    "        right_fit = np.polyfit(right_y, right_x, 2)\n",
    "    except TypeError:\n",
    "        left_fit, right_fit, output_buffer, right_x, right_y, left_x, left_y = sliding_window_lane_search(image, left_fit, right_fit)\n",
    "\n",
    "    output_buffer[nonzero_y[left_lane_indices], nonzero_x[left_lane_indices]] = [255, 0, 0]\n",
    "    output_buffer[nonzero_y[right_lane_indices], nonzero_x[right_lane_indices]] = [0, 0, 255]\n",
    "    return left_fit, right_fit,output_buffer, right_x, right_y, left_x, left_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in Test_images:\n",
    "    example_distorted_test_image = cv2.imread(fname)\n",
    "    example_distorted_test_image_RGB = cv2.cvtColor(example_distorted_test_image, cv2.COLOR_BGR2RGB)\n",
    "    example_undistorted_test_image = cv2.undistort(example_distorted_test_image_RGB,mtx,dist)\n",
    "    binary = generate_binary_image(example_undistorted_test_image)\n",
    "    warped, inverse_warp_matrix =warper_V2(binary)\n",
    "    left_fit, right_fit, out_image, _, _, _, _ = sliding_window_lane_search(warped, None, None)\n",
    "\n",
    "    if showimages:\n",
    "        # Generate x and y values for plotting\n",
    "        ploty = np.linspace(100, out_image.shape[0]-1, out_image.shape[0] )\n",
    "        left_fit_x = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fit_x = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        plt.figure(figsize=(20, 20))\n",
    "        plt.imshow(out_image)\n",
    "        plt.plot(left_fit_x, ploty, color='yellow')\n",
    "        plt.plot(right_fit_x, ploty, color='yellow')\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(223, 0)\n",
    "        fig=plt.figure(figsize=(20,10))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Computing Radius of Curvature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meters_per_pixel_y = 30/720 \n",
    "meters_per_pixel_x = 3.7/700 \n",
    "\n",
    "def radius_of_curvature(y_value, right_x, left_x, right_y, left_y):\n",
    "    # Fit new polynomials to x,y in world space\n",
    "    left_fit_cr = np.polyfit(left_y, left_x, 2)\n",
    "    right_fit_cr = np.polyfit(right_y, right_x, 2)\n",
    "    al, bl, cl = left_fit_cr\n",
    "    ar, br, cr = left_fit_cr\n",
    "    left = (1 + (((2 * al * y_value * meters_per_pixel_y) + bl) ** 2) ** (1.5))/ np.absolute(2 * al)\n",
    "    right = (1 + (((2 * ar * y_value * meters_per_pixel_y) + br) ** 2) ** (1.5))/ np.absolute(2 * ar)\n",
    "    return left, right\n",
    "\n",
    "def distance_from_center(left_fit, right_fit, y_value, x_size):\n",
    "    left_fit_x = left_fit[0]*y_value* meters_per_pixel_y**2 + left_fit[1]*y_value*meters_per_pixel_y + left_fit[2]\n",
    "    right_fit_x = right_fit[0]*y_value* meters_per_pixel_y**2 + right_fit[1]*y_value*meters_per_pixel_y + right_fit[2]\n",
    "    \n",
    "    center_of_car = x_size / 2\n",
    "    center_of_lane = (left_fit_x + right_fit_x) / 2\n",
    "    return (center_of_lane - center_of_car) * meters_per_pixel_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Drawing Detected Lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane_lines(warped_image, left_fit, right_fit, inverse_warp_matrix, destination_image):\n",
    "    # Image for drawing\n",
    "    destination_image = np.copy(destination_image)\n",
    "    warp_zero = np.zeros_like(warped_image).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    \n",
    "    ploty = np.linspace(100, warp_zero.shape[0]-1, warp_zero.shape[0] )\n",
    "    left_fit_x = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fit_x = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Convert x & y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fit_x, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fit_x, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, inverse_warp_matrix, ( 1280,720)) \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(destination_image, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return result\n",
    "    \n",
    "import datetime\n",
    "    \n",
    "def draw_radius_of_curvature(image, radius, last_draw):\n",
    "    \n",
    "    if (datetime.datetime.now() - last_draw).total_seconds() > 1:\n",
    "        last_draw = datetime.datetime.now()\n",
    "        radius = min_radius\n",
    "    \n",
    "    cv2.putText(\n",
    "        image,\n",
    "        \"Radius of Curvature: {radius} m\".format(radius=round(radius, 3)),\n",
    "        (10, 50),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1.1,\n",
    "        (255, 255, 255),\n",
    "        2,\n",
    "    )\n",
    "    return last_draw\n",
    "\n",
    "def draw_center_offset(left_fit, right_fit, image):\n",
    "    y_value = image.shape[0]\n",
    "    distance = distance_from_center(left_fit, right_fit, y_value, image.shape[1])\n",
    "    \n",
    "    cv2.putText(\n",
    "        image,\n",
    "        \"Offset from center of lane: {distance} m\".format(distance=round(distance, 3)),\n",
    "        (10, 150),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        1.1,\n",
    "        (255, 255, 255),\n",
    "        2,\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in Test_images:\n",
    "    example_distorted_test_image = cv2.imread(fname)\n",
    "    example_distorted_test_image_RGB = cv2.cvtColor(example_distorted_test_image, cv2.COLOR_BGR2RGB)\n",
    "    example_undistorted_test_image = cv2.undistort(example_distorted_test_image_RGB,mtx,dist)\n",
    "    binary = generate_binary_image(example_undistorted_test_image)\n",
    "    warped, inverse_warp_matrix =warper_V2(binary)\n",
    "    left_fit, right_fit, out, right_x, right_y, left_x, left_y = sliding_window_lane_search(warped, None, None)\n",
    "    new_image = draw_lane_lines(warped, left_fit, right_fit, inverse_warp_matrix, example_undistorted_test_image)\n",
    "    last_draw = datetime.datetime.now()\n",
    "    y_value = new_image.shape[0]\n",
    "    radius_left, radius_right = radius_of_curvature(y_value, right_x, left_x, right_y, left_y)\n",
    "    min_radius = min([radius_left, radius_right])\n",
    "    last_draw = draw_radius_of_curvature(new_image, min_radius, last_draw)\n",
    "    draw_center_offset(left_fit, right_fit, new_image)\n",
    "\n",
    "    if showimages:\n",
    "        fig=plt.figure(figsize=(20,10))\n",
    "        plt.subplot(121),plt.imshow(example_undistorted_test_image)\n",
    "        plt.title('Before', fontsize=30)\n",
    "        plt.subplot(122),plt.imshow(new_image)\n",
    "        plt.title('draw_lane_lines', fontsize=30)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Pipelining for Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global last_5_radius\n",
    "last_5_radius = []\n",
    "def lane_detector_pipeline(image, left, right):\n",
    "    image = np.copy(image)\n",
    "    undistorted_image = cv2.undistort(\n",
    "        image,\n",
    "        mtx,\n",
    "        dist\n",
    "    )\n",
    "    binary = generate_binary_image(undistorted_image)\n",
    "    warped, inverse_warp_matrix = warper_V2(binary)\n",
    "    if left is None and right is None:\n",
    "        left_fit, right_fit, out, right_x, right_y, left_x, left_y = sliding_window_lane_search(warped, left, right)\n",
    "    else:\n",
    "        left_fit, right_fit, out, right_x, right_y, left_x, left_y = preexisting_lane_search(warped, left, right)\n",
    "    drawn = draw_lane_lines(\n",
    "        warped,\n",
    "        left_fit,\n",
    "        right_fit,\n",
    "        inverse_warp_matrix,\n",
    "        undistorted_image\n",
    "    )\n",
    "    last_draw = datetime.datetime.now()\n",
    "    y_value = new_image.shape[0]\n",
    "    min_radius = min(radius_of_curvature(y_value, right_x, left_x, right_y, left_y))\n",
    "\n",
    "\n",
    "    if len(last_5_radius) == 5:\n",
    "        last_5_radius.pop()\n",
    "    last_5_radius.insert(0, min_radius)\n",
    "\n",
    "    last_draw = draw_radius_of_curvature(drawn, sum(last_5_radius) / len(last_5_radius), last_draw)\n",
    "    draw_center_offset(left_fit, right_fit, drawn)\n",
    "    color_binary = binary * 255\n",
    "    return drawn, left_fit, right_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageProcessor:\n",
    "    per_image_fit_left = None\n",
    "    per_image_fit_right = None\n",
    "    def process_image(self, image):\n",
    "        drawn, self.per_image_fit_left, self.per_image_fit_right = lane_detector_pipeline(image, self.per_image_fit_left, self.per_image_fit_right)\n",
    "        return drawn\n",
    "\n",
    "processor = ImageProcessor()\n",
    "    \n",
    "output = 'Project_Output/project_output_v3.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")#.subclip(0,10)\n",
    "project_clip = clip1.fl_image(processor.process_image) #NOTE: this function expects color images!!\n",
    "%time project_clip.write_videofile(output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}